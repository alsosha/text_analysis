{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4882c346",
   "metadata": {},
   "source": [
    "# Инструмент для обработки текста и подсчета слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686ed26",
   "metadata": {},
   "source": [
    "#### Привет! :) У тебя есть файл с текстом и тебе нужно посчитать в нем упоминания слов по частям речи? Ты обратился по адресу! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fc382",
   "metadata": {},
   "source": [
    "Инструмент состоит из нескольких функций с возможностью настройки (ниже оглавление с гиперссылками на часть файла):\n",
    "\n",
    "* [Считывание и запись файла формата txt или excel в переменную](#Считывание-файла)\n",
    "\n",
    "\n",
    "* [Очистка текста от знаков препинания, приведение к нижнему регистру](#Очистка-текста)\n",
    "\n",
    "\n",
    "* [Нормализация/лемматизация слов (приведение к начальной форме)](#Нормализация/лемматизация-слов)\n",
    "\n",
    "\n",
    "* [Подсчет слов и определение частей речи](#Подсчет-слов-по-частям-речи)\n",
    "\n",
    "\n",
    "* [Запись всех частей речи или только нужных тебе в таблицу excel](#Фильтрация-и-запись-в-таблицу)\n",
    "\n",
    "\n",
    "* [Справочный блок](#Установка-библиотек)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e7d06",
   "metadata": {},
   "source": [
    "Если в процессе работы у тебя возникнут предложения по улучшению инструмента, можно написать мне в тг: @esthesuntik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4247b0",
   "metadata": {},
   "source": [
    "*Примечание: код подразумевает, что все библиотеки для работы уже установлены. Справочный блок с информацией про то, как устанавливать необходимые пакеты находится в конце инструмента. Запускай его, только если впервые используешь ту или иную билиотеку*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b481a0",
   "metadata": {},
   "source": [
    "### Считывание файла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad963799",
   "metadata": {},
   "source": [
    "Сначала импортируем библиотеки для этого блока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#для работы с табличными данными\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "#для считывания файла формата .docx\n",
    "\n",
    "import docx\n",
    "\n",
    "\n",
    "#для устранения ошибок кодировки при чтении .txt\n",
    "\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c850ee7",
   "metadata": {},
   "source": [
    "! Файл с текстом, который ты собираешься обрабатывать, должен лежать в той же папке, что и файл инструмента (т.к. мы не прописываем точный путь к файлу в памяти устройства) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#впиши в кавычки название файла в формате: название.xlsx (.txt / .docx)\n",
    "\n",
    "file_name = 'file_name.docx'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2faf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#если тексты записаны в таблицу, впиши в переменную ниже название столбца, в котором они содержатся\n",
    "\n",
    "texts_column = 'Название_столбца'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#список с возможными формата файла для обработки\n",
    "\n",
    "possible_formats = ['xlsx', 'txt', 'docx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '.' not in file_name or file_name.split('.')[1] not in possible_formats:   #если что-то пошло не так\n",
    "    print('Упс, похоже что-то пошло не так. Алгоритм для такого формата не прописан или есть ошибка в названии файла :(')\n",
    "\n",
    "else:\n",
    "    n = 0\n",
    "    \n",
    "    if file_name.split('.')[1] == 'xlsx':        #если формат файла xlsx, то:\n",
    "        text_df = pd.read_excel(file_name)       #считываем и преобразуем таблицу в датафрейм\n",
    "        texts_list = list(text_df[texts_column]) #собираем тексты из ячеек в список строк\n",
    "        pre_text = ' '.join(texts_list)          #объединяем в одну строку через пробел\n",
    "        \n",
    "        n+=1\n",
    "\n",
    "    elif file_name.split('.')[1] == 'txt':                 #если формат файла txt, то:\n",
    "        txt_file = codecs.open(file_name, 'r', 'utf-8')    #открываем файл и записываем в переменную в формате строки\n",
    "\n",
    "        pre_text = ''\n",
    "        for line in txt_file:\n",
    "            pre_text += line.strip() + ' '\n",
    "\n",
    "        txt_file.close()\n",
    "        \n",
    "        n+=1\n",
    "\n",
    "    elif file_name.split('.')[1] == 'docx':      #если формат файла docx, то:\n",
    "        doc_file = docx.Document(file_name)      #считываем файл и записываем в переменную в формате строки\n",
    "\n",
    "        pre_text = ''\n",
    "        for par in doc_file.paragraphs:\n",
    "            pre_text += par.text\n",
    "            \n",
    "        n+=1\n",
    "        \n",
    "    if n == 1:\n",
    "        print('Ура! Текст успешно обработан и записан в переменную \"pre_text\" в формате строки')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7de065",
   "metadata": {},
   "source": [
    "### Очистка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7c43e",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords             #стоп-слова (некоторые предлоги, местоимения и т.д.)\n",
    "ru_stopwords = stopwords.words('russian')\n",
    "\n",
    "from string import punctuation                #знаки препинания и символы (ниже через плюс можно добавить свои)\n",
    "punctuation = punctuation + '—' + '«' + '»' + '–' + '…' + '№' + '0123456789'\n",
    "\n",
    "from emoji import is_emoji                    #определение эмодзи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0899f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(punctuation)   #от каких знаков препинания и символов избавляемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e38f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ru_stopwords)   #от каких стоп-слов избавляемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a35993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#если не хочешь избавляться от стоп-слов, поставь значение переменной ниже False (без кавычек)\n",
    "\n",
    "#хочешь убрать стоп-слова, ставь значение True (без кавычек)\n",
    "\n",
    "no_stopwords = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c325c9e",
   "metadata": {},
   "source": [
    "Функция очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(words_status, text):\n",
    "    \n",
    "    new_text = ''\n",
    "    \n",
    "    for part in text.split('\\n'):         #убираем перенос строки, если он есть\n",
    "        if part != '':\n",
    "            new_text += part\n",
    "            \n",
    "    no_punct_text = ''\n",
    "    \n",
    "    for symbol in new_text:\n",
    "        if symbol not in punctuation and not is_emoji(symbol):        #удаляем знаки препинания и символы\n",
    "            no_punct_text += symbol.lower()\n",
    "        if symbol == '.':\n",
    "            no_punct_text += ' '\n",
    "            \n",
    "    while '  ' in no_punct_text:                          #убираем двойные пробелы\n",
    "        no_punct_text = no_punct_text.replace('  ', ' ')     \n",
    "    \n",
    "    if words_status == True:       #если нужно, удаляем стоп-слова\n",
    "        return ' '.join([word for word in no_punct_text.split() if word not in ru_stopwords])\n",
    "    \n",
    "    elif words_status == False:    #если не нужно, то возвращаем просто текст без знаков препинания\n",
    "        return no_punct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83552430",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = text_cleaner(no_stopwords, pre_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3776a",
   "metadata": {},
   "source": [
    "### Нормализация/лемматизация слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd907f",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy3 import MorphAnalyzer           #для приведения слов к начальной форме\n",
    "pymorphy3_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d026e",
   "metadata": {},
   "source": [
    "Функция лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lemmatizer(text):\n",
    "    res = [pymorphy3_analyzer.parse(word)[0].normal_form for word in text.split()]\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_text = text_lemmatizer(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a26d0b",
   "metadata": {},
   "source": [
    "### Подсчет слов по частям речи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e0ca8",
   "metadata": {},
   "source": [
    "Ниже можно подсчитать два вида частоты слова в тексте:\n",
    "- абсолютную: число повторений слова в тексте\n",
    "- относительную: доля числа употреблений слова от общего числа токенов (единиц текста, т.е. неуникальных слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78d60d",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fa26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter   #упрощает подсчет повтора слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18088128",
   "metadata": {},
   "source": [
    "Считаем абсолютную и относительную частоту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4dba2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_count = Counter()\n",
    "\n",
    "words = []\n",
    "count_abs = []   #список для значений абсолютной частоты\n",
    "count_rel = []   #список для значений относительной частоты\n",
    "\n",
    "normal_list = normal_text.split()\n",
    "tokens_count = len(normal_list)\n",
    "    \n",
    "for word in normal_list:\n",
    "    word_count[word] += 1        #формируем словарь с числом повторений слов              \n",
    "\n",
    "n = 1 \n",
    "for para in word_count.most_common(len(word_count)):    #распределеяем словарь в два списка (слова, значения) и считаем относительную частоту\n",
    "    words.append(para[0])                                     \n",
    "    count_abs.append(para[1])\n",
    "    count_rel.append(para[1]/tokens_count)\n",
    "    print(f'{n}.{para[0]} - {para[1]}')       #смотрим на результат: вывод слов и абсолютной частоты\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b422e9",
   "metadata": {},
   "source": [
    "Определяем части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caaed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gramems = []\n",
    "\n",
    "for word in words:\n",
    "    p = pymorphy3_analyzer.parse(word)[0]\n",
    "    tags = (str(p.tag)).split(',')\n",
    "    gramems.append(tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ac2de",
   "metadata": {},
   "source": [
    "Формируем датафрейм со всеми частями речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame({'words' : words, 'gramems' : gramems, 'count' : count_abs, 'share' : count_rel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.head()     #Посмотрим на начало датафрейма"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f79c2d",
   "metadata": {},
   "source": [
    "### Фильтрация и запись в таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6c31e",
   "metadata": {},
   "source": [
    "В библиотеке есть свое обозначений частей речи (граммемы). По ним мы будем отфильтровывать только нужные нам слова. Полный список с примерами ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47eeb5d",
   "metadata": {},
   "source": [
    "| Граммема      | Значение                         | Пример         |\n",
    "| :------------ | :------------------------------- | :------------- |\n",
    "| NOUN          | Имя существительное              | Человек        |\n",
    "| ADJF          | Имя прилагательное (полное)      | Хороший        |\n",
    "| ADJS          | Имя прилагательное (краткое)     | Хорош          |\n",
    "| COMP          | Компаратив                       | Быстрее, лучше |\n",
    "| VERB          | Глагол (личная форма)            | Говорю         |\n",
    "| INFN          | Глагол (инфинитив)               | Говорить       |\n",
    "| PRTF          | Причастие (полное)               | Прочитанная    |\n",
    "| PRTS          | Причастие (краткое)              | Прочитана      |\n",
    "| GRND          | Деепричастие                     | Рассказывая    |\n",
    "| NUMR          | Числительное                     | Три, сорок     |\n",
    "| ADVB          | Наречие                          | Весело         |\n",
    "| NPRO          | Местоимение-существительное      | Он, она        |\n",
    "| PRED          | Предикатив (категория состояния) | Некогда        |\n",
    "| PREP          | Предлог                          | Предлог        |\n",
    "| CONJ          | Союз                             | И              |\n",
    "| PRCL          | Частица                          | Бы, же, лишь   |\n",
    "| INTJ          | Междометие                       | Ой             |\n",
    "| LATN          | Латинские буквы                  | Hello          |\n",
    "| PNCT          | Пунктуация                       | !?             |\n",
    "| NUMB          | Число                            | 125            |\n",
    "| ROMN          | Римское число                    | XI             |\n",
    "| UNKN          | Не удалось разобрать             |                |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777123ea",
   "metadata": {},
   "source": [
    "Подробнее тут: https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e634a0",
   "metadata": {},
   "source": [
    "В переменную ниже впиши, какой фильтр тебе нужен. Возможные варианты:\n",
    "\n",
    "* СУЩ (только существительные)\n",
    "* ПРИЛ (только прилагательные, попадают и местоимения-прилагательные)\n",
    "* ГЛАГ (только глаголы)\n",
    "* НАРЕЧ (только наречия)\n",
    "* СМЫСЛЫ (вместе сущ, прил, глаг и нареч)\n",
    "* ДРУГОЕ (пользовательский фильтр, см. ниже)\n",
    "* ВСЕ (все части речи, перечисленные в таблице выше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#впиши в кавычки нужный тебе вариант\n",
    "\n",
    "grammems_filter = 'ДРУГОЕ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538772ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#если ты выбрал 'ДРУГОЕ', то можешь собрать свой фильтр из граммем из таблицы. Замени, убери или добавь значения в списке ниже\n",
    "\n",
    "user_filter = ['NOUN', 'ADJF', 'ADJS', 'COMP', 'VERB', 'INFN', 'ADVB', 'INTJ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab04d04",
   "metadata": {},
   "source": [
    "Теперь отфлитруем датафрейм по твоему запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grammems_filter == 'СУЩ':\n",
    "    filtered_df = words_df[words_df.gramems == 'NOUN']\n",
    "    \n",
    "elif grammems_filter == 'ПРИЛ':\n",
    "    filtered_df = words_df[words_df.gramems.isin(['ADJF', 'ADJS', 'COMP'])]\n",
    "    \n",
    "elif grammems_filter == 'ГЛАГ':\n",
    "    filtered_df = words_df[words_df.gramems.isin(['VERB', 'INFN'])]\n",
    "    \n",
    "elif grammems_filter == 'НАРЕЧ':\n",
    "    filtered_df = words_df[words_df.gramems == 'ADVB']\n",
    "    \n",
    "elif grammems_filter == 'СМЫСЛЫ':\n",
    "    filtered_df = words_df[words_df.gramems.isin(['NOUN', 'ADJF', 'ADJS', 'COMP', 'VERB', 'INFN', 'ADVB'])]\n",
    "    \n",
    "elif grammems_filter == 'ДРУГОЕ':\n",
    "    filtered_df = words_df[words_df.gramems.isin(user_filter)]\n",
    "    \n",
    "elif grammems_filter == 'ВСЕ':\n",
    "    filtered_df = words_df\n",
    "    \n",
    "else:\n",
    "    print('Похоже, такого фильтра не существует :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cda1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на начало отфильтрованного датафрейма\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a4e15",
   "metadata": {},
   "source": [
    "Сохраняем датафрейм в файл формата xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff16232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Впиши в кавычки ниже название для нового файла в формате 'Таблица.xlsx'\n",
    "\n",
    "df_name = 'file_name.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d09cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(df_name)    #Сохраняем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b852a",
   "metadata": {},
   "source": [
    "Готово! Теперь у тебя есть данные, с которыми можно дальше работать. Удачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8afd0dc",
   "metadata": {},
   "source": [
    "### Установка библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc00199",
   "metadata": {},
   "source": [
    "Чтобы установить библиотеку, убери # в начале строки и запусти ячейку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords')      # загрузка корпуса стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea05d-7776-4207-b5a9-7f11d65df53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade27291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymorphy3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
